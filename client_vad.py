#!/usr/bin/env python3
"""
WebSocket å®¢æˆ·ç«¯ï¼Œæ”¯æŒ WebRTC VAD è¯­éŸ³æ´»åŠ¨æ£€æµ‹
è‡ªåŠ¨æ£€æµ‹è¯­éŸ³æ®µï¼Œé™éŸ³åè‡ªåŠ¨å‘é€éŸ³é¢‘
"""

import asyncio
import json
import base64
import time
import uuid
from collections import deque

import numpy as np
import pyaudio
import webrtcvad
import websockets

# ============ é…ç½® ============
SERVER_URL = "ws://127.0.0.1:8000/ws"
CLIENT_ID = f"client_{uuid.uuid4().hex[:8]}"

# éŸ³é¢‘è¾“å…¥è®¾å¤‡ (None=é»˜è®¤ï¼Œæˆ–æŒ‡å®šè®¾å¤‡ç´¢å¼•å¦‚ 0)
AUDIO_DEVICE_INDEX = None  # è®¾ä¸º 0 ä½¿ç”¨ HDA Intel PCH

# éŸ³é¢‘é…ç½®
SAMPLE_RATE = 16000  # é‡‡æ ·ç‡ (WebRTC VAD æ”¯æŒ 8k/16k/32k)
CHANNELS = 1         # å•å£°é“
FRAME_DURATION_MS = 30  # å¸§æ—¶é•¿ (WebRTC VAD æ”¯æŒ 10/20/30ms)
FRAME_SIZE = int(SAMPLE_RATE * FRAME_DURATION_MS / 1000)  # æ¯å¸§é‡‡æ ·æ•°
BYTES_PER_SAMPLE = 2  # 16bit = 2 bytes
FRAME_BYTES = FRAME_SIZE * CHANNELS * BYTES_PER_SAMPLE

# VAD é…ç½®
VAD_AGGRESSIVENESS = 0  # 0-3, è¶Šå¤§è¶Šæ¿€è¿›è¿‡æ»¤éè¯­éŸ³
SILENCE_THRESHOLD_MS = 5000  # é™éŸ³é˜ˆå€¼ï¼Œè¶…è¿‡æ­¤æ—¶é—´è®¤ä¸ºè¯´è¯ç»“æŸ
MIN_SPEECH_DURATION_MS = 500  # æœ€å°è¯­éŸ³æ—¶é•¿ï¼Œè¿‡çŸ­çš„å¿½ç•¥


class VADAudioClient:
    def __init__(self):
        self.vad = webrtcvad.Vad(VAD_AGGRESSIVENESS)
        self.audio = pyaudio.PyAudio()
        
        # éŸ³é¢‘ç¼“å†²åŒº
        self.audio_buffer = deque()
        self.speech_frames = []
        
        # çŠ¶æ€
        self.is_speaking = False
        self.last_speech_time = 0
        self.speech_start_time = 0
        
    def list_audio_devices(self):
        """åˆ—å‡ºæ‰€æœ‰éŸ³é¢‘è®¾å¤‡"""
        print("\nå¯ç”¨éŸ³é¢‘è¾“å…¥è®¾å¤‡:")
        for i in range(self.audio.get_device_count()):
            info = self.audio.get_device_info_by_index(i)
            if info['maxInputChannels'] > 0:
                print(f"  [{i}] {info['name']} (è¾“å…¥é€šé“: {info['maxInputChannels']})")
        print()
        
    def is_speech(self, frame: bytes) -> bool:
        """æ£€æµ‹å¸§æ˜¯å¦åŒ…å«è¯­éŸ³"""
        return self.vad.is_speech(frame, SAMPLE_RATE)
    
    def process_audio(self, websocket):
        """ä¸»éŸ³é¢‘å¤„ç†å¾ªç¯"""
        stream = self.audio.open(
            format=pyaudio.paInt16,
            channels=CHANNELS,
            rate=SAMPLE_RATE,
            input=True,
            input_device_index=AUDIO_DEVICE_INDEX,
            frames_per_buffer=FRAME_SIZE,
        )
        
        print(f"éº¦å…‹é£å·²å¼€å¯ï¼Œé‡‡æ ·ç‡: {SAMPLE_RATE}Hz, VAD æ¨¡å¼: {VAD_AGGRESSIVENESS}")
        print("å¼€å§‹ç›‘å¬... (è¯´è¯åè‡ªåŠ¨å‘é€ï¼ŒæŒ‰ Ctrl+C é€€å‡º)\n")
        
        silence_frame_count = 0
        silence_frames_needed = SILENCE_THRESHOLD_MS // FRAME_DURATION_MS
        min_speech_frames = MIN_SPEECH_DURATION_MS // FRAME_DURATION_MS
        
        try:
            while True:
                frame = stream.read(FRAME_SIZE, exception_on_overflow=False)
                is_speech = self.is_speech(frame)
                current_time = time.time()
                
                if is_speech:
                    if not self.is_speaking:
                        # å¼€å§‹è¯´è¯
                        self.is_speaking = True
                        self.speech_start_time = current_time
                        self.speech_frames = []
                        print("ğŸ™ï¸ æ£€æµ‹åˆ°è¯­éŸ³å¼€å§‹...")
                    
                    self.speech_frames.append(frame)
                    self.last_speech_time = current_time
                    silence_frame_count = 0
                else:
                    if self.is_speaking:
                        silence_frame_count += 1
                        # é™éŸ³æœŸé—´ä¹Ÿæ”¶é›†å¸§ï¼ˆé˜²æ­¢åˆ‡æ–­å°¾éŸ³ï¼‰
                        self.speech_frames.append(frame)
                        
                        # æ£€æŸ¥æ˜¯å¦è¶…è¿‡é™éŸ³é˜ˆå€¼
                        if silence_frame_count >= silence_frames_needed:
                            self.is_speaking = False
                            speech_duration = (current_time - self.speech_start_time) * 1000
                            
                            # ç§»é™¤å°¾éƒ¨é™éŸ³å¸§
                            actual_speech_frames = len(self.speech_frames) - silence_frame_count
                            
                            if actual_speech_frames >= min_speech_frames:
                                print(f"âœ… è¯­éŸ³ç»“æŸï¼Œæ—¶é•¿: {speech_duration:.0f}msï¼Œå‘é€ä¸­...")
                                # å‘é€éŸ³é¢‘
                                audio_data = b''.join(self.speech_frames[:-silence_frame_count])
                                asyncio.run(self.send_audio(websocket, audio_data))
                            else:
                                print(f"â­ï¸ è¯­éŸ³è¿‡çŸ­ ({speech_duration:.0f}ms)ï¼Œå¿½ç•¥")
                            
                            self.speech_frames = []
                            silence_frame_count = 0
        finally:
            stream.stop_stream()
            stream.close()
    
    async def send_audio(self, websocket, audio_data: bytes):
        """å‘é€éŸ³é¢‘åˆ°æœåŠ¡å™¨"""
        audio_base64 = base64.b64encode(audio_data).decode('utf-8')
        
        message = {
            "multimodal": [
                {"type": "text", "text": "[ç”¨æˆ·å‘é€äº†éŸ³é¢‘æ¶ˆæ¯]"}
            ],
            "audio": audio_base64
        }
        
        try:
            await websocket.send(json.dumps(message))
            print("ğŸ“¤ éŸ³é¢‘å·²å‘é€ï¼Œç­‰å¾…å“åº”...\n")
        except Exception as e:
            print(f"âŒ å‘é€å¤±è´¥: {e}")
    
    async def receive_messages(self, websocket):
        """æ¥æ”¶æœåŠ¡å™¨æ¶ˆæ¯"""
        try:
            async for message in websocket:
                # æµå¼æ¥æ”¶ï¼Œç›´æ¥æ‰“å°
                print(message, end='', flush=True)
        except websockets.exceptions.ConnectionClosed:
            print("\nè¿æ¥å·²å…³é—­")
    
    async def run(self):
        """ä¸»è¿è¡Œå‡½æ•°"""
        uri = f"{SERVER_URL}/{CLIENT_ID}"
        print(f"è¿æ¥åˆ°: {uri}")
        
        try:
            async with websockets.connect(uri) as websocket:
                print("âœ… WebSocket å·²è¿æ¥\n")
                
                # å¯åŠ¨æ¥æ”¶ä»»åŠ¡
                receive_task = asyncio.create_task(self.receive_messages(websocket))
                
                # åœ¨çº¿ç¨‹ä¸­è¿è¡ŒéŸ³é¢‘å¤„ç†
                loop = asyncio.get_event_loop()
                await loop.run_in_executor(None, self.process_audio, websocket)
                
                receive_task.cancel()
                
        except websockets.exceptions.ConnectionClosedError as e:
            print(f"è¿æ¥è¢«æ‹’ç»æˆ–å…³é—­: {e}")
        except KeyboardInterrupt:
            print("\n\nç”¨æˆ·ä¸­æ–­ï¼Œé€€å‡º...")
        finally:
            self.audio.terminate()


def main():
    print("=" * 50)
    print("WebSocket VAD éŸ³é¢‘å®¢æˆ·ç«¯")
    print("=" * 50)
    
    client = VADAudioClient()
    client.list_audio_devices()
    
    asyncio.run(client.run())


if __name__ == "__main__":
    main()
